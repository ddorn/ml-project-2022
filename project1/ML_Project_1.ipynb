{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87713261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c6520",
   "metadata": {},
   "source": [
    "# Loading Higgs Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71237916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA = Path().resolve() / \"data\"\n",
    "print(\"Looking for the data in\", DATA)\n",
    "_,  tx_submission,  ids_submission  = load_csv_data(DATA / \"test.csv\")\n",
    "y, tx, _ = load_csv_data(DATA / \"train.csv\")\n",
    "\n",
    "# Split the data into training and testing\n",
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88766c74",
   "metadata": {},
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_histograms(tx_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(tx, mean=None, std=None, enable=True):\n",
    "    if not enable:\n",
    "        return tx\n",
    "\n",
    "    # Feature 22 is an integer, on which many other features are based.\n",
    "    # We add 4 new features for each of the 4 possible values of feature 22.\n",
    "    tx_22 = tx[:, [22]]\n",
    "    tx_22 = np.repeat(tx_22, 4, axis=1)\n",
    "    tx_22 = tx_22 == [0, 1, 2, 3]\n",
    "    tx = np.concatenate((tx, tx_22), axis=1)\n",
    "\n",
    "    # Some features look like the exponential of some variable, so\n",
    "    # we add a features that are the log of them\n",
    "    tx_log = np.log(tx[:, [2, 9, 10, 13, 16, 19, 21]])\n",
    "    tx = np.concatenate((tx, tx_log), axis=1)\n",
    "    \n",
    "    # Some features are angles, so we add their sine and cosine\n",
    "    angles = np.array([14, 15, 17, 18, 20])\n",
    "    tx = np.concatenate((tx, np.sin(tx[:, angles]), np.cos(tx[:, angles])), axis=1)\n",
    "\n",
    "    # Feature 29 is zero when f22 < 2 because it is the sum\n",
    "    # of the undefined features. Should we put it at -999?\n",
    "    # Should we split it into two features?\n",
    "\n",
    "    \n",
    "    # Some features are undefined if f_22 < 2\n",
    "    # undef_from_22 = [4, 6, 12, 23, 24, 25, 26, 27, 28]\n",
    "    # new = tx[:, undef_from_22]\n",
    "    # new[new == -999] = 0\n",
    "    # tx = np.concatenate((tx, new), axis=1)\n",
    "\n",
    "    # We add the powers of each feature\n",
    "    powers = [2, 3, 4]\n",
    "    # features = [1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 16, 19, 21, 29, \n",
    "    #     34, 35, 36, 37, 38, 39, 40]\n",
    "    features = [1, 3, 5, 7, 8, 11, 29, \n",
    "        34, 35, 36, 37, 38, 39, 40]\n",
    "    for p in powers:\n",
    "        tx = np.concatenate((tx, tx[:, features] ** p), axis=1)\n",
    "\n",
    "    # We add the product of each pair of features\n",
    "    for f1 in features:\n",
    "        for f2 in features:\n",
    "            if f1 < f2:\n",
    "                tx = np.concatenate((tx, tx[:, [f1]] * tx[:, [f2]]), axis=1)\n",
    "\n",
    "    # Normalisation\n",
    "\n",
    "    assert (mean is None) == (std is None), f\"{mean=} {std=}\"\n",
    "    if mean is None:\n",
    "        # We don't normalize every feature.\n",
    "        # We don't normalise features that are discrete, angular\n",
    "        # Or where the 0 seems to be a special value (f_11)\n",
    "        dont_normalise = {11, 14, 15, 17, 18, 20, 22}\n",
    "        # dont_normalise.update(np.where(np.min(tx_train, axis=0) >= 0)[0])\n",
    "        dont_normalise = list(dont_normalise)\n",
    "\n",
    "        mean = np.mean(tx, axis=0)\n",
    "        std = np.std(tx, axis=0)\n",
    "        mean[dont_normalise] = 0\n",
    "        std[dont_normalise] = 1\n",
    "\n",
    "    std[std == 0] = 1  # The feature is constant\n",
    "    tx = (tx - mean) / std\n",
    "\n",
    "    return tx, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_histograms(feature_engineering(tx_train)[0], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f13f5",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(tx, y, threshold=50, just_plot=False, enable=True):\n",
    "    \"\"\"Remove outliers from the dataset.\n",
    "    Outliers are defined as points that are more than threshold times the standard\n",
    "    deviation away from the mean.\n",
    "    \"\"\"\n",
    "\n",
    "    if not enable:\n",
    "        return tx, y\n",
    "        \n",
    "    weirdness = np.sum(np.abs(normalize_features(tx)[0]), axis=1)\n",
    "    print(f'Number of samples above {threshold} deviations in total: {np.sum(weirdness > threshold)}')\n",
    "\n",
    "    if just_plot:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.hist(weirdness, bins=100)\n",
    "        plt.xlabel('sum of deviations from the mean')\n",
    "        plt.ylabel('number of samples')\n",
    "        plt.title('Histogram of weirdness')\n",
    "        plt.show()\n",
    "    else:\n",
    "        tx = tx[weirdness < threshold]\n",
    "        y = y[weirdness < threshold]\n",
    "        return tx, y\n",
    "\n",
    "remove_outliers(tx_train, y_train, just_plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620faa4f",
   "metadata": {},
   "source": [
    "# Training one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094dd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(weights, tx):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    y_pred = np.einsum('rf,f->r', tx, weights)\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(y, tx, predictor):\n",
    "    \"\"\"Compute the accuracy of the model.\"\"\"\n",
    "    y_pred = predictor(tx)\n",
    "    return np.sum(y_pred == y) / len(y)\n",
    "\n",
    "def show_accuracy(y, tx, y_test, tx_test, predictor):\n",
    "    print(f\"Accuracy on training set: {accuracy(y, tx, predictor):.4f}\")\n",
    "    print(f\"Accuracy on test set: {accuracy(y_test, tx_test, predictor):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_OUTLIERS = 1\n",
    "ADD_FEATURES = 1\n",
    "\n",
    "tx, y_clean = remove_outliers(tx_train, y_train, threshold=50, enable=RM_OUTLIERS)\n",
    "tx_clean, mean, std = feature_engineering(tx, enable=ADD_FEATURES)\n",
    "tx_test_clean, _, _ = feature_engineering(tx_test, mean, std, enable=ADD_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_iters': 300,\n",
    "    'gamma': 0.01,\n",
    "    'lambda_': 0.001,\n",
    "    'batch_size': 400,\n",
    "    'initial_w': np.random.randn(tx_clean.shape[1]),\n",
    "}\n",
    "weigths, losses = mean_squared_error_sgd(y_clean, tx_clean, **params, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "smooth_loss = np.convolve(losses[10000:], np.ones(1000) / 1000, mode='valid')\n",
    "plt.plot(np.linspace(0, params['max_iters'], len(smooth_loss)), smooth_loss)\n",
    "show_accuracy(y_clean, tx_clean, y_test, tx_test_clean, lambda tx: predict_labels(weigths[-1], tx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91a739",
   "metadata": {},
   "source": [
    "# Training multiple models\n",
    "Depending on feature 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing accuracy depending on the value of feature 22\n",
    "for f_22 in range(4):\n",
    "    mask = tx_clean[:, 22] == f_22\n",
    "    acc = accuracy(y_clean[mask], tx_clean[mask], lambda tx: predict_labels(weigths[-1], tx))\n",
    "    print(f\"Accuracy for f_22 = {f_22}: {acc:.4f} ({np.sum(mask)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "normalisation = []\n",
    "losses = []\n",
    "for f_22 in range(4):\n",
    "    mask = tx_train[:, 22] == f_22\n",
    "\n",
    "    tx, y_clean = remove_outliers(tx_train[mask], y_train[mask], threshold=50, enable=1)\n",
    "    tx_clean, mean, std = feature_engineering(tx, enable=ADD_FEATURES)\n",
    "    normalisation.append((mean, std))\n",
    "\n",
    "    params['initial_w'] = np.random.randn(tx_clean.shape[1])\n",
    "    model, loss = mean_squared_error_sgd(y_clean, tx_clean, **params)\n",
    "    models.append(model)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_22(models, tx):\n",
    "    y_pred = np.zeros(tx.shape[0])\n",
    "    for f_22, w in enumerate(models):\n",
    "        mask = tx[:, 22] == f_22\n",
    "        y_pred[mask] = predict_labels(w, tx[mask])\n",
    "    return y_pred\n",
    "\n",
    "# Normalising the test set, but with the 4 different normalisations\n",
    "def normalise_22(tx, normalisations):\n",
    "    nb_features = feature_engineering(tx[[0],:])[0].shape[1]\n",
    "    result = np.zeros((tx.shape[0], nb_features))\n",
    "    for f_22, (mean, std) in enumerate(normalisation):\n",
    "        mask = tx[:, 22] == f_22\n",
    "        result[mask], _, _ = feature_engineering(tx[mask], mean, std, enable=ADD_FEATURES)\n",
    "    return result\n",
    "\n",
    "tx_test_22 = normalise_22(tx_test, normalisation)\n",
    "tx_train_22 = normalise_22(tx_train, normalisation)\n",
    "show_accuracy(y_train, tx_train_22, y_test, tx_test_22, lambda tx: predict_labels_22(models, tx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4f52c",
   "metadata": {},
   "source": [
    "# Predicting the unkown labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faf71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_submission_2 = normalise_22(tx_submission, normalisation)\n",
    "y_submission = predict_labels_22(models, tx_submission_2)\n",
    "create_csv_submission(ids_submission, y_submission, \"second-attempt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf20dff",
   "metadata": {},
   "source": [
    "# Comparision of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the accuracy of the two models, depending on the value of feature 22\n",
    "for f_22 in range(4):\n",
    "    mask = tx_test[:, 22] == f_22\n",
    "    acc_22 = accuracy(y_test[mask], tx_test_22[mask], lambda tx: predict_labels_22(models, tx))\n",
    "    acc = accuracy(y_test[mask], tx_test_clean[mask], lambda tx: predict_labels(weigths[-1], tx))\n",
    "    print(f\"Accuracy for f_22 = {f_22}: {acc_22:.4f} vs {acc:.4f} ({np.sum(mask)} samples)\")\n",
    "\n",
    "# total accuracy\n",
    "acc_22 = accuracy(y_test, tx_test_22, lambda tx: predict_labels_22(models, tx))\n",
    "acc = accuracy(y_test, tx_test_clean, lambda tx: predict_labels(weigths[-1], tx))\n",
    "print(f\"Total accuracy: {acc_22:.4f} vs {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
